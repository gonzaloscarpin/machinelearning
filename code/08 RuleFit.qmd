---
title: "Random forest"
format: html
---

# Setup  
```{r}
#| message: false
#| warning: false
library(tidymodels)
library(tidyverse)
library(vip)
library(sf)
library(rules)
library(finetune)
library(doParallel)
tidymodels_prefer()
```

# 1) M + W + S + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```


```{r final_spec}
final_spec <- rule_fit(mtry = best_r2_3$mtry, 
           trees = best_r2_3$trees, 
           min_n = best_r2_3$min_n, 
           tree_depth = best_r2_3$tree_depth, 
           learn_rate = best_r2_3$learn_rate, 
           loss_reduction = best_r2_3$loss_reduction, 
           sample_size = best_r2_3$sample_size, 
           penalty = best_r2_3$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =67.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+W+S+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+W+S+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 2) M + W + S
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60#,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_3$mtry, 
           trees = best_rmse_3$trees, 
           min_n = best_rmse_3$min_n, 
           tree_depth = best_rmse_3$tree_depth, 
           learn_rate = best_rmse_3$learn_rate, 
           loss_reduction = best_rmse_3$loss_reduction, 
           sample_size = best_rmse_3$sample_size, 
           penalty = best_rmse_3$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=71.9),
                        position_eq = c(x=75, y =69.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+W+S.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+W+S_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 3) M + W + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                stage_duration_emergence:stage_vp_total,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_2$mtry, 
           trees = best_rmse_2$trees, 
           min_n = best_rmse_2$min_n, 
           tree_depth = best_rmse_2$tree_depth, 
           learn_rate = best_rmse_2$learn_rate, 
           loss_reduction = best_rmse_2$loss_reduction, 
           sample_size = best_rmse_2$sample_size, 
           penalty = best_rmse_2$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=78,y=73),
                        position_eq = c(x=75, y =71))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+W+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+W+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 4) M + S + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =67.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+S+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+S+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 5) M + W + S + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_3$mtry, 
           trees = best_rmse_3$trees, 
           min_n = best_rmse_3$min_n, 
           tree_depth = best_rmse_3$tree_depth, 
           learn_rate = best_rmse_3$learn_rate, 
           loss_reduction = best_rmse_3$loss_reduction, 
           sample_size = best_rmse_3$sample_size, 
           penalty = best_rmse_3$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =67.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/W+S+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/W+S+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 6) M + W
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                stage_duration_emergence:stage_vp_total#,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =71.8))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+W.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+W_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 7) M + S
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60#,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =67.9))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+S.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+S_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 8) M + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_2$mtry, 
           trees = best_rmse_2$trees, 
           min_n = best_rmse_2$min_n, 
           tree_depth = best_rmse_2$tree_depth, 
           learn_rate = best_rmse_2$learn_rate, 
           loss_reduction = best_rmse_2$loss_reduction, 
           sample_size = best_rmse_2$sample_size, 
           penalty = best_rmse_2$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=73,y=81),
                        position_eq = c(x=77, y =81))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 9) W + S
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60#,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=71.5),
                        position_eq = c(x=75, y =69))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/W+S.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/W+S_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 10) W + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                stage_duration_emergence:stage_vp_total,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=81.5),
                        position_eq = c(x=75, y =70.9))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/W+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/W+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 11) S + O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_2$mtry, 
           trees = best_rmse_2$trees, 
           min_n = best_rmse_2$min_n, 
           tree_depth = best_rmse_2$tree_depth, 
           learn_rate = best_rmse_2$learn_rate, 
           loss_reduction = best_rmse_2$loss_reduction, 
           sample_size = best_rmse_2$sample_size, 
           penalty = best_rmse_2$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =67.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/S+O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/S+O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 12) M 
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, planting_date:variety, 
                row_pattern:saved_seed, 
                lat, lon#, 
                #stage_duration_emergence:stage_vp_total,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_3$mtry, 
           trees = best_rmse_3$trees, 
           min_n = best_rmse_3$min_n, 
           tree_depth = best_rmse_3$tree_depth, 
           learn_rate = best_rmse_3$learn_rate, 
           loss_reduction = best_rmse_3$loss_reduction, 
           sample_size = best_rmse_3$sample_size, 
           penalty = best_rmse_3$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =71.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/M.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/M_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 13) W 
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                stage_duration_emergence:stage_vp_total#,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse$mtry, 
           trees = best_rmse$trees, 
           min_n = best_rmse$min_n, 
           tree_depth = best_rmse$tree_depth, 
           learn_rate = best_rmse$learn_rate, 
           loss_reduction = best_rmse$loss_reduction, 
           sample_size = best_rmse$sample_size, 
           penalty = best_rmse$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.5),
                        position_eq = c(x=75, y =71.4))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/W.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/W_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 14) S
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                river_basin, soil_series,
                soil_clay_0_5:soil_theta_s_30_60#,
                #NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_3$mtry, 
           trees = best_rmse_3$trees, 
           min_n = best_rmse_3$min_n, 
           tree_depth = best_rmse_3$tree_depth, 
           learn_rate = best_rmse_3$learn_rate, 
           loss_reduction = best_rmse_3$loss_reduction, 
           sample_size = best_rmse_3$sample_size, 
           penalty = best_rmse_3$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=75,y=70.8),
                        position_eq = c(x=75, y =71.4))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/S.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/S_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```

# 15) O
# Yield
```{r }
df <- read_sf("../data/data_complete.geojson") %>% 
  st_drop_geometry() %>% 
  as.data.frame() %>% 
  dplyr::select(planting_date, digger_date, growing_season, variety, river_basin, soil_series, row_pattern, 
                irrigation, saved_seed, 
                tillage_method=tillage_method_simplify,
                rotation = rotation_simplify_years_wo_peanut, seeding_rate, 
                grade_n, 
                alt, stage_duration_emergence:elevation,
                lat= lat.y, lon = long
                ) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(rotation = as.factor(rotation)) %>% 
  dplyr::select(-(c(alt, rotation, seeding_rate, tillage_method))) %>% 
  dplyr::select(!(c(soil_alpha_0_5:soil_bd_30_60, 
                    soil_hb_0_5:soil_hb_30_60, 
                    soil_lambda_0_5:soil_n_30_60,
                    soil_theta_r_0_5:soil_theta_r_30_60
                    ))) %>%
  #dplyr::select(-(c("lat", "lon"))) %>% 
  
  dplyr::select(-(c(SCI:NGRDI))) %>% 
  dplyr::select(grade_n, 
                #planting_date:variety, 
                #row_pattern:saved_seed, 
                #lat, lon, 
                #stage_duration_emergence:stage_vp_total,
                #river_basin, soil_series,
                #soil_clay_0_5:soil_theta_s_30_60,
                NDVI:elevation
                ) %>% 
  #dplyr::select(-(c(NDVI:GNDVI, elevation))) %>% 
  drop_na() %>% dplyr::filter(grade_n > 65) 

df
```


# ML workflow  
## 1. Pre-processing  
### a. Data split  
For data split, let's use **70% training / 30% testing**.
```{r weather_split}
# Setting seed to get reproducible results  
set.seed(27)
weather_split <- initial_split(df, prop = 0.7, 
                               strata = "grade_n")
weather_split
```
```{r weather_train}
# Setting train set 
weather_train <- training(weather_split)

weather_train
```


```{r weather_test}
# Setting test split
weather_test <- testing(weather_split)

weather_test
```
```{r data distribution}
# Combine the data frames
plot_train <- weather_train %>% mutate(Dataset = "Train")
plot_test <- weather_test %>% mutate(Dataset = "Test")
combined_data <- bind_rows(plot_train, plot_test)

# Create the density plot
ggplot(data = combined_data) +
  geom_density(aes(x = grade_n, fill = Dataset), alpha = 0.5) +
  scale_fill_manual(values = c("red", "blue")) +
  labs(x = "Yield (kg/ha)", y = "Density", fill = "Dataset")
```
  
### b. Data processing  
```{r weather_recipe}
weather_recipe <-
  # Defining predicted and predictor variables
  recipe(grade_n ~ .,
         data = weather_train) %>%
  step_dummy(all_factor_predictors()) %>%
  step_zv(all_numeric_predictors()) %>% 
  step_normalize(all_predictors()) 

weather_recipe
```

```{r weather_prep}
weather_prep <- weather_recipe %>%
  prep()

weather_prep
```
## 2. Training  
### a. Model specification  
```{r hyperparameters}
rule_fit_xrf_spec <-
  rule_fit(mtry = tune(), 
           trees = tune(), 
           min_n = tune(), 
           tree_depth = tune(), 
           learn_rate = tune(), 
           loss_reduction = tune(), 
           sample_size = tune(), 
           penalty = tune()
           ) %>%
  set_engine('xrf',
             counts = FALSE
             ) %>%
  set_mode('regression')

rule_fit_xrf_spec
```

### b. Hyper-parameter tuning  
  
```{r resampling_foldcv}
set.seed(15)
resampling_foldcv <- vfold_cv(weather_train, 
                              v = 5)

resampling_foldcv
```
```{r rf_grid_result}
set.seed(45)
registerDoParallel(cores = parallel::detectCores() - 1)
rf_grid_result <- tune_race_anova(object = rule_fit_xrf_spec,
                      preprocessor = weather_recipe,
                      resamples = resampling_foldcv,
                     #param_info = rf_param,
                     grid = 50
                      )
stopImplicitCluster()
rf_grid_result$.metrics[[5]]
```

```{r hyperparameters selection by RMSE}
# Based on lowest RMSE
best_rmse <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rmse",
                     limit = 2
                     )%>% 
  mutate(source = "best_rmse")

best_rmse_2 <- rf_grid_result %>% 
  select_best(metric = "rmse")%>% 
  mutate(source = "best_rmse_2")

best_rmse_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rmse",
                        
                        tree_depth
                        )%>% 
  mutate(source = "best_rmse_3")

best_rmse
best_rmse_2
best_rmse_3

```

```{r hyperparameters selection by R2}
# Based on greatest R2
best_r2 <- rf_grid_result %>% 
  select_by_pct_loss("trees",
                     metric = "rsq",
                     limit = 2
                     ) %>% 
  mutate(source = "best_r2")

best_r2_2 <- rf_grid_result %>% 
  select_best(metric = "rsq")%>% 
  mutate(source = "best_r2_2")

best_r2_3 <- rf_grid_result %>% 
  select_by_one_std_err(metric = "rsq",
                        
                        tree_depth
                        ) %>%
  mutate(source = "best_r2_3")

best_r2
best_r2_2
best_r2_3
```

```{r comparing values}
hyperparameters_df <- best_rmse %>% 
  bind_rows(best_rmse_2, best_rmse_3, best_r2, best_r2_2, best_r2_3)
```

```{r}
# Function to find the best model
compare_hyperparameters <- function(params_df, recipe, split) {
  # Create empty tibble to store results
  results <- tibble(
    mtry = numeric(),
    trees = numeric(),
    min_n = numeric(),
    tree_depth = numeric(),
    learn_rate = numeric(),
    loss_reduction = numeric(),
    sample_size = numeric(),
    penalty = numeric(),
    rmse = numeric(),
    source = character()
  )
  
  # Loop through each row of parameters
  for(i in 1:nrow(params_df)) {
    # Extract current parameters
    current_params <- params_df[i, ]
    
    # Create model specification
    set.seed(10)
    current_spec <- rule_fit(
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
      ) %>%
      set_engine("xrf",
                 count = F
                 ) %>%
      set_mode('regression')
    
    # Fit model and collect metrics
    current_fit <- last_fit(current_spec, 
                            recipe, 
                            split = split)
    current_metrics <- current_fit %>% 
      collect_metrics()
    
    # Extract RMSE value
    current_rmse <- current_metrics %>% 
      filter(.metric == "rmse") %>% 
      pull(.estimate)
    
    # Store results
    results <- results %>% add_row(
      source = current_params$source,
      rmse = current_rmse,
      mtry = current_params$mtry,
      trees = current_params$trees,
      min_n = current_params$min_n,
      tree_depth = current_params$tree_depth,
      learn_rate = current_params$learn_rate,
      loss_reduction = current_params$loss_reduction,
      sample_size = current_params$sample_size,
      penalty = current_params$penalty
    )
  }
  
  # Find the best combination
  best_params <- results %>% 
    arrange(rmse) %>% 
    dplyr::slice_head(n = 1)
  
  return(list(
    all_results = results,
    best_combination = best_params
  ))
}

# Example usage
results <- compare_hyperparameters(
  params_df = hyperparameters_df,
  recipe = weather_recipe,
  split = weather_split
)
print(results)
```

```{r final_spec}
final_spec <- rule_fit(mtry = best_rmse_2$mtry, 
           trees = best_rmse_2$trees, 
           min_n = best_rmse_2$min_n, 
           tree_depth = best_rmse_2$tree_depth, 
           learn_rate = best_rmse_2$learn_rate, 
           loss_reduction = best_rmse_2$loss_reduction, 
           sample_size = best_rmse_2$sample_size, 
           penalty = best_rmse_2$penalty
                     ) %>% 
  # Specify the engine
  set_engine("xrf", 
             count = F) %>%
  # Specifying mode  
  set_mode("regression")

final_spec
```

## 3. Validation  
```{r final_fit}
set.seed(10)
final_fit <- last_fit(final_spec,
                weather_recipe,
                split = weather_split)

final_fit %>%
  collect_predictions()
```
Metrics on the **test set**:
```{r}
final_fit %>%
  collect_metrics()
```
Metrics on **train set** (for curiosity and compare to test set):  
```{r}
# RMSE
final_spec %>%
  fit(grade_n ~ .,
      data = bake(weather_prep, 
                  weather_train)) %>%
  augment(new_data = bake(weather_prep, 
                          weather_train)) %>% 
  rmse(grade_n, .pred) %>%
  bind_rows(
    
    
    # R2
    final_spec %>%
      fit(grade_n ~ .,
          data = bake(weather_prep, 
                      weather_train)) %>%
      augment(new_data = bake(weather_prep, 
                              weather_train)) %>% 
      rsq(grade_n, .pred)
    
  )

```
```{r predicted vs. observed plot}
plot <- final_fit %>%
  collect_predictions() %>%
  metrica::scatter_plot(obs = grade_n,
                        pred = .pred,
                        print_eq = T,
                        print_metrics = T,
                        metrics_list = c("R2", "RMSE"),
                      # Customize metrics position
                        position_metrics = c(x=73,y=80.5),
                        position_eq = c(x=73, y =78.5))

plot
```


```{r export first plot}
ggsave(plot = plot,
       filename = "../output/ML_Grade/06_RuleFit/O.png",
       width = 5,
       height = 5
       )
```

### Variable importance: 

```{r plotting VI}
# Fit the k-NN model
knn_fit <- final_spec %>%
  fit(grade_n ~ ., data = bake(weather_prep, df))

# Define a custom prediction function
predict_knn <- function(object, newdata) {
  predict(object, new_data = newdata)$.pred
}

# Calculate permutation importance, supplying the raw training data and custom prediction function
variable_importance <- vip::vi(knn_fit, method = "permute", target = "grade_n", metric = "rmse", train = bake(weather_prep, df), pred_wrapper = predict_knn)
# Create the plot
plot_2 <- variable_importance %>%
  mutate(
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  slice_head(n=10) %>% 
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)

plot_2

```


```{r export second plot}
ggsave(plot = plot_2,
       filename = "../output/ML_Grade/06_RuleFit/O_2.png",
       width = 5,
       height = 5,
       bg = "white"
       ) 
```
